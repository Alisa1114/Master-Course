{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "class train_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path, transform=None, training=True):\n",
    "        self.classes = [2, 4, 5, 6, 7]\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.img_path = []\n",
    "        self.labels = []\n",
    "        self.training = training\n",
    "\n",
    "        for l in self.classes:\n",
    "            labelPath = join(dataset_path, str(l))\n",
    "            file_names = [\n",
    "                f for f in listdir(labelPath) if isfile(join(labelPath, f))\n",
    "            ]\n",
    "\n",
    "            for file_name in file_names:\n",
    "                self.img_path.append([join(labelPath, file_name), file_name])\n",
    "                self.labels.append(self.classes.index(l))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, name = self.img_path[index]\n",
    "        image = Image.open(path)\n",
    "        if self.training:\n",
    "            image = image.rotate(180)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.labels[index]\n",
    "      \n",
    "class test_dataset(Dataset):\n",
    "    def __init__(self, dataset_path, transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.img_path = []\n",
    "        file_names = [f for f in listdir(dataset_path) if isfile(join(dataset_path, f))]\n",
    "        file_names.sort()\n",
    "        for file_name in file_names:\n",
    "            self.img_path.append([join(dataset_path, file_name), file_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, name = self.img_path[index]\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.rotate(image, cv2.ROTATE_180)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [2, 4, 5, 6, 7]\n",
    "train_data =  train_dataset('hw1/Training_data',\n",
    "                         transform=transforms.Compose([transforms.Grayscale(), transforms.ToTensor()]))\n",
    "train_loader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
    "\n",
    "valid_data = train_dataset('hw1/MNIST/valid',\n",
    "                         transform=transforms.Compose([transforms.Grayscale(), transforms.ToTensor()]),\n",
    "                         training=False)\n",
    "valid_loader = DataLoader(valid_data, batch_size=512, shuffle=False)\n",
    "\n",
    "# test_data = test_dataset('Testing_data1', transform=transforms.ToTensor())\n",
    "# test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "          nn.Conv2d(1, 6, 5),\n",
    "          nn.Dropout(0.2),\n",
    "          nn.BatchNorm2d(6),\n",
    "          nn.ReLU(True),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "          nn.Conv2d(6, 16, 5),\n",
    "          nn.BatchNorm2d(16),\n",
    "          nn.Dropout(0.2),\n",
    "          nn.ReLU(True),\n",
    "          nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(nn.Linear(4 * 4 * 16, 120), \n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.BatchNorm1d(120),\n",
    "                                nn.ReLU(True), \n",
    "                                nn.Linear(120, 84),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.BatchNorm1d(84),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Linear(84, num_classes))\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet(len(labels)).to(device)\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 16, 4, 4]            --\n",
      "|    └─Conv2d: 2-1                       [-1, 6, 24, 24]           156\n",
      "|    └─Dropout: 2-2                      [-1, 6, 24, 24]           --\n",
      "|    └─BatchNorm2d: 2-3                  [-1, 6, 24, 24]           12\n",
      "|    └─ReLU: 2-4                         [-1, 6, 24, 24]           --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 6, 12, 12]           --\n",
      "|    └─Conv2d: 2-6                       [-1, 16, 8, 8]            2,416\n",
      "|    └─BatchNorm2d: 2-7                  [-1, 16, 8, 8]            32\n",
      "|    └─Dropout: 2-8                      [-1, 16, 8, 8]            --\n",
      "|    └─ReLU: 2-9                         [-1, 16, 8, 8]            --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 16, 4, 4]            --\n",
      "├─Sequential: 1-2                        [-1, 5]                   --\n",
      "|    └─Linear: 2-11                      [-1, 120]                 30,840\n",
      "|    └─Dropout: 2-12                     [-1, 120]                 --\n",
      "|    └─BatchNorm1d: 2-13                 [-1, 120]                 240\n",
      "|    └─ReLU: 2-14                        [-1, 120]                 --\n",
      "|    └─Linear: 2-15                      [-1, 84]                  10,164\n",
      "|    └─Dropout: 2-16                     [-1, 84]                  --\n",
      "|    └─BatchNorm1d: 2-17                 [-1, 84]                  168\n",
      "|    └─ReLU: 2-18                        [-1, 84]                  --\n",
      "|    └─Linear: 2-19                      [-1, 5]                   425\n",
      "==========================================================================================\n",
      "Total params: 44,453\n",
      "Trainable params: 44,453\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.33\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.07\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.24\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 16, 4, 4]            --\n",
       "|    └─Conv2d: 2-1                       [-1, 6, 24, 24]           156\n",
       "|    └─Dropout: 2-2                      [-1, 6, 24, 24]           --\n",
       "|    └─BatchNorm2d: 2-3                  [-1, 6, 24, 24]           12\n",
       "|    └─ReLU: 2-4                         [-1, 6, 24, 24]           --\n",
       "|    └─MaxPool2d: 2-5                    [-1, 6, 12, 12]           --\n",
       "|    └─Conv2d: 2-6                       [-1, 16, 8, 8]            2,416\n",
       "|    └─BatchNorm2d: 2-7                  [-1, 16, 8, 8]            32\n",
       "|    └─Dropout: 2-8                      [-1, 16, 8, 8]            --\n",
       "|    └─ReLU: 2-9                         [-1, 16, 8, 8]            --\n",
       "|    └─MaxPool2d: 2-10                   [-1, 16, 4, 4]            --\n",
       "├─Sequential: 1-2                        [-1, 5]                   --\n",
       "|    └─Linear: 2-11                      [-1, 120]                 30,840\n",
       "|    └─Dropout: 2-12                     [-1, 120]                 --\n",
       "|    └─BatchNorm1d: 2-13                 [-1, 120]                 240\n",
       "|    └─ReLU: 2-14                        [-1, 120]                 --\n",
       "|    └─Linear: 2-15                      [-1, 84]                  10,164\n",
       "|    └─Dropout: 2-16                     [-1, 84]                  --\n",
       "|    └─BatchNorm1d: 2-17                 [-1, 84]                  168\n",
       "|    └─ReLU: 2-18                        [-1, 84]                  --\n",
       "|    └─Linear: 2-19                      [-1, 5]                   425\n",
       "==========================================================================================\n",
       "Total params: 44,453\n",
       "Trainable params: 44,453\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.33\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.07\n",
       "Params size (MB): 0.17\n",
       "Estimated Total Size (MB): 0.24\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(model,torch.rand(1,1,28,28).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10  Accuracy: 98.8348%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10  Accuracy: 99.0392%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10  Accuracy: 99.2641%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 10  Accuracy: 98.9575%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10  Accuracy: 99.1210%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10  Accuracy: 99.0392%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10  Accuracy: 99.2845%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10  Accuracy: 99.3459%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10  Accuracy: 99.3868%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:03, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 10  Accuracy: 99.1006%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "exp_name = 'project2_mnist_with_both.txt'\n",
    "f = open(exp_name, 'w')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for i, (image, label) in tqdm(enumerate(train_loader)):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('Epoch: {} / {}  Loss: {}'.format(epoch+1, epochs, loss.item()))\n",
    "\n",
    "        writer.add_scalar('Train Loss', loss.item(), epoch*len(train_loader)+i)\n",
    "\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            outputs = model(image)\n",
    "            predict = outputs.argmax(dim=-1)\n",
    "            accuracy += (predict == label).sum().item()\n",
    "            total += label.shape[0]\n",
    "\n",
    "        print('Epoch {} / {}  Accuracy: {:.4f}%'.format(epoch+1, epochs, 100*(accuracy/total)))\n",
    "        writer.add_scalar('Valid Accuracy', 100 * (accuracy / total), epoch)\n",
    "\n",
    "        f.write('{}\\n'.format(100 * (accuracy / total)))\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('711183116.txt', 'w') as f:\n",
    "#   for img, file_name in test_loader:\n",
    "#     img = img.to(device)\n",
    "#     output = model(img)\n",
    "#     predict = output.argmax(dim=-1)\n",
    "    \n",
    "#     print('{} {}\\n'.format(file_name[0].split('.')[0], labels[predict]))\n",
    "#     f.write('{} {}\\n'.format(file_name[0].split('.')[0], labels[predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f11f329b739e069ee571d9dc315b22363bc0f5d5f61058b9d390d5111cbd0926"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
