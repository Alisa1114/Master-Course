{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Import需要的library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.special import expit\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 讀取dataset並回傳圖片跟label的函式\n",
    "* label_folders: 要讀取的labels\n",
    "* dataset_path: 要讀取的資料集路徑\n",
    "* preprocessing: 是否要做一些圖片的前處理，主要是把圖片轉成1D vector並normalize到0~1之間\n",
    "* encoding: 是否要對labels做one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset(label_folders, dataset_path='MNIST/train', preprocessing=True, encoding=True):\n",
    "  img_list = []\n",
    "  label_list = []\n",
    "  enc = OneHotEncoder(handle_unknown='ignore')\n",
    "  label_folders = np.array(label_folders).reshape(-1, 1)\n",
    "  enc.fit(label_folders)\n",
    "  \n",
    "  # print(enc.categories_)\n",
    "\n",
    "  for l in label_folders:\n",
    "    labelPath = join(dataset_path, str(l.item()))\n",
    "    file_names = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "\n",
    "    for file_name in file_names:\n",
    "      img_path = join(labelPath, file_name)\n",
    "      img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "      if preprocessing:\n",
    "        img = cv2.rotate(img, cv2.ROTATE_180) # 不知為何助教給的圖片轉了180度，所以在這裡轉回來\n",
    "        img = img.reshape(-1).astype('float32')\n",
    "        img /= 255.0\n",
    "        \n",
    "      l_enc = l  \n",
    "      if encoding:\n",
    "        # print(l)\n",
    "        l_enc = enc.transform([l]).toarray()[0]\n",
    "        # print(l_enc)\n",
    "      \n",
    "      img_list.append(img)\n",
    "      label_list.append(l_enc)\n",
    "\n",
    "  return np.array(img_list), np.array(label_list)\n",
    "\n",
    "def test_dataset(dataset_path, preprocessing=True):\n",
    "  def takeSecond(elem):\n",
    "    return elem[1]\n",
    "  \n",
    "  data_list = []\n",
    "  \n",
    "  file_names = [f for f in listdir(dataset_path)]\n",
    "  file_names.sort()\n",
    "  \n",
    "  for file_name in file_names:\n",
    "    img_path = join(dataset_path, file_name) # 'mnist_testData/Tesing_data/0000.png'\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if preprocessing:\n",
    "      img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "      img = img.reshape(-1).astype('float32')\n",
    "      img /= 255.0\n",
    "    \n",
    "    data_list.append((img, file_name))\n",
    "    # data_list.sort(key=takeSecond)\n",
    "    \n",
    "  return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 讀取dataset，讓它回傳數字2, 4, 5, 6, 7的圖片和labels\n",
    "* images shape: [number of images, height * width]\n",
    "* labels shape: [number of labels, number of classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [2, 4, 5, 6, 7]\n",
    "training_images, training_labels = dataset(classes, dataset_path='Training_data')\n",
    "# valid_images, valid_labels = dataset(classes, dataset_path='MNIST/valid', encoding=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### $Sigmoid(x) = \\frac{1}{1 + \\exp^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  # return 1.0 / (1.0 + np.exp(-x))\n",
    "  return expit(x) # avoid overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 搭建model為一個class\n",
    "* feed_forward: 做feed forward\n",
    "* train_model: 丟入dataset和超參數來訓練模型\n",
    "* update: 利用back propagation更新模型\n",
    "* back_propagation: 計算$\\Delta w$和$\\Delta b$\n",
    "* predict: 預測圖片的label值\n",
    "* compute_cost: 計算error，也就是講義裡的$\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "class neural_network():\n",
    "  def __init__(self, sizes):\n",
    "    \"\"\"suppose sizes=[2, 3, 4], weights would be [3, 2], [4, 3], biases would be [3, 1], [4, 1]\"\"\"\n",
    "    self.sizes = sizes\n",
    "    self.num_layer = len(self.sizes)\n",
    "    self.weights = [np.random.randn(self.sizes[i], self.sizes[i-1]) for i in range(1, self.num_layer)]\n",
    "    self.biases = [np.random.randn(self.sizes[i], 1) for i in range(1, self.num_layer)]\n",
    "    self.last_delta_w = [np.zeros((self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layer)]\n",
    "    self.last_delta_b = [np.zeros((self.sizes[i], 1)) for i in range(1, self.num_layer)]\n",
    "    self.momentum = 0.0\n",
    "    \n",
    "  def feed_forward(self, a):\n",
    "    for w, b in zip(self.weights, self.biases):\n",
    "      a = sigmoid(np.dot(w, a) + b)\n",
    "      \n",
    "    return a\n",
    "  \n",
    "  def train_model(self, images, labels, num_epoch, learning_rate, batch_size, valid_images=None, valid_labels=None, momentum=0.0):\n",
    "    n = len(images)\n",
    "    self.momentum = momentum\n",
    "    \n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "      \n",
    "      images, labels = shuffle(images, labels)\n",
    "     \n",
    "      mini_batches_images = [images[i:i+batch_size] for i in range(0, n, batch_size)]\n",
    "      mini_batches_labels = [labels[i:i+batch_size] for i in range(0, n, batch_size)]\n",
    "      \n",
    "      for image, label in zip(mini_batches_images, mini_batches_labels):\n",
    "        self.update(learning_rate, image,label)\n",
    "      \n",
    "      # Calculate test data accuracy\n",
    "      if valid_images is not None:\n",
    "        acc = 0.0\n",
    "        for image, label in zip(valid_images, valid_labels):\n",
    "          result = self.predict(image)\n",
    "          if classes[result] == label.item():\n",
    "            acc += 1\n",
    "        print('Epoch {} / {}     Accuracy : {}'.format(epoch+1, num_epoch, acc/len(valid_images)))\n",
    "  \n",
    "  def update(self, learning_rate, image, label):\n",
    "    \n",
    "    delta_weight, delta_bias = self.back_propagation(image, label)\n",
    "    \n",
    "    self.weights = [w + learning_rate * delta_w/len(image) for w, delta_w in zip(self.weights, delta_weight)]\n",
    "    self.biases = [b + learning_rate * delta_b/len(image) for b, delta_b in zip(self.biases, delta_bias)] \n",
    "    \n",
    "    self.last_delta_w = [w for w in delta_weight]\n",
    "    self.last_delta_b = [b for b in delta_bias]       \n",
    "      \n",
    "  \n",
    "  def back_propagation(self, image, label):\n",
    "    delta_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "    delta_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "    \n",
    "    activations = [image.T]\n",
    "    activation = image.T\n",
    "    \n",
    "    for w, b in zip(self.weights, self.biases):\n",
    "      activation = sigmoid(np.dot(w, activation) + b)\n",
    "      activations.append(activation)\n",
    "      \n",
    "    delta = self.compute_cost(label.T, activations)\n",
    "    \n",
    "    for i, (a_i, delta_j) in enumerate(zip(activations, delta)):\n",
    "      delta_weights[i] = self.momentum * self.last_delta_w[i] + delta_weights[i] + np.dot(delta_j, a_i.T)\n",
    "      delta_biases[i] = self.momentum * self.last_delta_b[i] + delta_biases[i] + delta_j.sum(axis=-1, keepdims=True)\n",
    "        \n",
    "    return delta_weights, delta_biases\n",
    "  \n",
    "  def predict(self, test_data):\n",
    "    # test_data: [784]\n",
    "    y = self.feed_forward(test_data[...,None]) # [784, 1] -> [10, 1]\n",
    "    results = np.argmax(y, axis=0) # [0.1, 0.3, 0.2, 0.4, 0.9, 0.4, 0.3, 0.4, 0.1, 0.5] -> [4]\n",
    "  \n",
    "    return results.item() # 4\n",
    "    \n",
    "  def compute_cost(self, label, activation):\n",
    "    delta = []\n",
    "    w = self.weights[::-1]\n",
    "    for i, a in enumerate(activation[-1:0:-1]): #從最後一個往回取到index=1\n",
    "      \n",
    "      if i == 0:\n",
    "        delta.append((label - a) * a * (1.0 - a))   \n",
    "      else:\n",
    "        delta.append(a * (1.0 - a) * (np.dot(w[i-1].T, delta[i-1])))\n",
    "    \n",
    "    return delta[::-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 初始化並訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = neural_network([training_images.shape[-1], 1024, 256, 64, len(classes)])\n",
    "model.train_model(training_images, \n",
    "                  training_labels, \n",
    "                  num_epoch=50, \n",
    "                  learning_rate=0.1, \n",
    "                  batch_size=8,\n",
    "                  momentum=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 儲存模型權重\n",
    "~~但我自己沒測試過能不能用就是了~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "checkpoint = {}\n",
    "checkpoint['weights'] = model.weights\n",
    "checkpoint['biases'] = model.biases\n",
    "\n",
    "with open('checkpoint.pickle', 'wb') as f:\n",
    "  pickle.dump(checkpoint, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### 預測助教給的test set，並將結果寫進txt檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "  \n",
    "data_list = test_dataset('Testing_data1') # (image, file_name) * length of list\n",
    "\n",
    "with open('711183116.txt', 'w') as f:\n",
    "  for img, file_name in data_list:\n",
    "    result = model.predict(img)\n",
    "    print('{} {}\\n'.format(file_name.split('.')[0], classes[result]))\n",
    "    f.write('{} {}\\n'.format(file_name.split('.')[0], classes[result]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f11f329b739e069ee571d9dc315b22363bc0f5d5f61058b9d390d5111cbd0926"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
