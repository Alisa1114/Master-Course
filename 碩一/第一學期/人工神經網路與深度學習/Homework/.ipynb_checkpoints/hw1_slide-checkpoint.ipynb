{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Import the packages we need\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.special import expit\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm.auto import tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Read the training and testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## dataset\n",
    "* label_folders: labels we want\n",
    "* dataset_path: path of dataset\n",
    "* preprocessing: whether to do image preprocessing，includes transform images into 1D vector and normalize them between 0~1\n",
    "* encoding: whether to do one hot encoding to labels\n",
    "* return: list of images, list of labels\n",
    "\n",
    "```python\n",
    "def dataset(label_folders, dataset_path='MNIST/train', preprocessing=True, encoding=True):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    label_folders = np.array(label_folders).reshape(-1, 1)\n",
    "    enc.fit(label_folders)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Read images from directory\n",
    "\n",
    "```python\n",
    "  for l in label_folders:\n",
    "    labelPath = join(dataset_path, str(l.item()))\n",
    "    file_names = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "\n",
    "    for file_name in file_names:\n",
    "      img_path = join(labelPath, file_name)\n",
    "      img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "      if preprocessing:\n",
    "        img = cv2.rotate(img, cv2.ROTATE_180) # 不知為何助教給的圖片轉了180度，所以在這裡轉回來\n",
    "        img = img.reshape(-1).astype('float32')\n",
    "        img /= 255.0\n",
    "        \n",
    "      l_enc = l  \n",
    "      if encoding:\n",
    "        l_enc = enc.transform([l]).toarray()[0]\n",
    "      \n",
    "      img_list.append(img)\n",
    "      label_list.append(l_enc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## test_set\n",
    "* dataset_path: testing set path\n",
    "* preprocessing: whether to do image preprocessing，includes transform images into 1D vector and normalize them between 0~1\n",
    "\n",
    "```python\n",
    "def test_dataset(dataset_path, preprocessing=True):\n",
    "  def takeSecond(elem):\n",
    "    return elem[1]\n",
    "  \n",
    "  data_list = []\n",
    "  file_names = [f for f in listdir(dataset_path)]\n",
    "  file_names.sort()\n",
    "  \n",
    "  for file_name in file_names:\n",
    "    img_path = join(dataset_path, file_name) # 'mnist_testData/Tesing_data/0000.png'\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if preprocessing:\n",
    "      img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "      img = img.reshape(-1).astype('float32')\n",
    "      img /= 255.0\n",
    "    data_list.append((img, file_name))\n",
    "    \n",
    "  return data_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Read the dataset, let function return the training set images and labels\n",
    "* images shape: [number of images, height * width]\n",
    "* labels shape: [number of labels, number of classes]\n",
    "\n",
    "```python\n",
    "classes = [2, 4, 5, 6, 7]\n",
    "training_images, training_labels = dataset(classes, dataset_path='Training_data')\n",
    "# valid_images, valid_labels = dataset(classes, dataset_path='MNIST/valid', encoding=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Compute Sigmoid function\n",
    "\n",
    "$$Sigmoid(x) = \\frac{1}{1 + \\exp^{-x}}$$\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "  # return 1.0 / (1.0 + np.exp(-x))\n",
    "  return expit(x) # avoid overflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Build model with python class\n",
    "* feed forward\n",
    "* train_model\n",
    "* update\n",
    "* back_propagation\n",
    "* predict\n",
    "* compute_cost\n",
    "\n",
    "```python\n",
    "class neural_network()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Initialization\n",
    "```python\n",
    "  def __init__(self, sizes):\n",
    "    \"\"\"suppose sizes=[2, 3, 4], weights would be [3, 2], [4, 3], biases would be [3, 1], [4, 1]\"\"\"\n",
    "    self.sizes = sizes\n",
    "    self.num_layer = len(self.sizes)\n",
    "    self.weights = [np.random.randn(self.sizes[i], self.sizes[i-1]) for i in range(1, self.num_layer)]\n",
    "    self.biases = [np.random.randn(self.sizes[i], 1) for i in range(1, self.num_layer)]\n",
    "    self.last_delta_w = [np.zeros((self.sizes[i], self.sizes[i-1])) for i in range(1, self.num_layer)]\n",
    "    self.last_delta_b = [np.zeros((self.sizes[i], 1)) for i in range(1, self.num_layer)]\n",
    "    self.momentum = 0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## feed forward\n",
    "\n",
    "$$a_j = f(\\sum_{i} w_{ji}a_{i})$$\n",
    "```python\n",
    "  def feed_forward(self, a):\n",
    "    for w, b in zip(self.weights, self.biases):\n",
    "      a = sigmoid(np.dot(w, a) + b)\n",
    "    return a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Send the dataset and hyperparameter, and train the model\n",
    "```python\n",
    "def train_model(self, images, labels, num_epoch, learning_rate, batch_size, valid_images=None, valid_labels=None, momentum=0.0):\n",
    "    n = len(images)\n",
    "    self.momentum = momentum\n",
    "    \n",
    "    for epoch in tqdm(range(num_epoch)):  \n",
    "      images, labels = shuffle(images, labels)\n",
    "     \n",
    "      mini_batches_images = [images[i:i+batch_size] for i in range(0, n, batch_size)]\n",
    "      mini_batches_labels = [labels[i:i+batch_size] for i in range(0, n, batch_size)]\n",
    "      \n",
    "      for image, label in zip(mini_batches_images, mini_batches_labels):\n",
    "        self.update(learning_rate, image,label)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Calculate validation data accuracy\n",
    "```python\n",
    "      if valid_images is not None:\n",
    "        acc = 0.0\n",
    "        for image, label in zip(valid_images, valid_labels):\n",
    "          result = self.predict(image)\n",
    "          if classes[result] == label.item():\n",
    "            acc += 1\n",
    "        print('Epoch {} / {}     Accuracy : {}'.format(epoch+1, num_epoch, acc/len(valid_images)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Update the model by back propagation\n",
    "\n",
    "```python\n",
    "  def update(self, learning_rate, image, label):\n",
    "    \n",
    "    delta_weight, delta_bias = self.back_propagation(image, label)\n",
    "    \n",
    "    self.weights = [w + learning_rate * delta_w/len(image) for w, delta_w in zip(self.weights, delta_weight)]\n",
    "    self.biases = [b + learning_rate * delta_b/len(image) for b, delta_b in zip(self.biases, delta_bias)] \n",
    "    \n",
    "    self.last_delta_w = [w for w in delta_weight]\n",
    "    self.last_delta_b = [b for b in delta_bias]     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Do back propagation\n",
    "\n",
    "$$\\Delta w_{ji}(n) = \\alpha\\Delta w_{ji}(n-1) + \\eta\\delta_ja_i$$\n",
    "\n",
    "```python\n",
    "def back_propagation(self, image, label):\n",
    "    delta_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "    delta_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "    \n",
    "    activations = [image.T]\n",
    "    activation = image.T\n",
    "    \n",
    "    for w, b in zip(self.weights, self.biases):\n",
    "      activation = sigmoid(np.dot(w, activation) + b)\n",
    "      activations.append(activation)\n",
    "      \n",
    "    delta = self.compute_cost(label.T, activations)\n",
    "    \n",
    "    for i, (a_i, delta_j) in enumerate(zip(activations, delta)):\n",
    "      delta_weights[i] = self.momentum * self.last_delta_w[i] + delta_weights[i] + np.dot(delta_j, a_i.T)\n",
    "      delta_biases[i] = self.momentum * self.last_delta_b[i] + delta_biases[i] + delta_j.sum(axis=-1, keepdims=True)\n",
    "        \n",
    "    return delta_weights, delta_biases\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Compute error\n",
    "\n",
    "$$\\delta_j = \n",
    "\\begin{cases}\n",
    "(d_j - a_j)a_j(1 - a_j) & \\text{, if } j \\text{ is an output unit} \\\\\n",
    "a_j(1 - a_j)\\sum_{k=1}^{n(n\\in h+1)}\\delta_{k,h+1}w_{kj,h+1}, & \\text{, if } j \\text{ is an hidden unit}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "```python\n",
    "def compute_cost(self, label, activation):\n",
    "    delta = []\n",
    "    w = self.weights[::-1]\n",
    "    for i, a in enumerate(activation[-1:0:-1]): #從最後一個往回取到index=1\n",
    "      if i == 0:\n",
    "        delta.append((label - a) * a * (1.0 - a))   \n",
    "      else:\n",
    "        delta.append(a * (1.0 - a) * (np.dot(w[i-1].T, delta[i-1])))\n",
    "    return delta[::-1]  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Predict the label of the image\n",
    "```python\n",
    "  def predict(self, test_data):\n",
    "    # test_data: [784]\n",
    "    y = self.feed_forward(test_data[...,None]) # [784, 1] -> [10, 1]\n",
    "    results = np.argmax(y, axis=0) # [0.1, 0.3, 0.2, 0.4, 0.9, 0.4, 0.3, 0.4, 0.1, 0.5] -> [4]\n",
    "  \n",
    "    return results.item() # 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Declare a new model, and train it\n",
    "```python\n",
    "model = neural_network([training_images.shape[-1], 1024, 256, 64, len(classes)])\n",
    "model.train_model(training_images, \n",
    "                  training_labels, \n",
    "                  num_epoch=50, \n",
    "                  learning_rate=0.1, \n",
    "                  batch_size=8,\n",
    "                  momentum=0.05)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Save the model\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "checkpoint = {}\n",
    "checkpoint['weights'] = model.weights\n",
    "checkpoint['biases'] = model.biases\n",
    "\n",
    "with open('checkpoint.pickle', 'wb') as f:\n",
    "  pickle.dump(checkpoint, f)\n",
    "```\n",
    "~~I haven't test it lol~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Predict test set, and write the results into a text file  \n",
    "```python\n",
    "data_list = test_dataset('Testing_data1') # (image, file_name) * length of list\n",
    "\n",
    "with open('711183116.txt', 'w') as f:\n",
    "  for img, file_name in data_list:\n",
    "    result = model.predict(img)\n",
    "    print('{} {}\\n'.format(file_name.split('.')[0], classes[result]))\n",
    "    f.write('{} {}\\n'.format(file_name.split('.')[0], classes[result]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Thank you for watching!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f11f329b739e069ee571d9dc315b22363bc0f5d5f61058b9d390d5111cbd0926"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
